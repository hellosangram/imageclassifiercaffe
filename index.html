<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <title>Image Classifier Caffe by hellosangram</title>
    <link rel="stylesheet" href="stylesheets/styles.css">
    <link rel="stylesheet" href="stylesheets/github-dark.css">
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.7.1/jquery.min.js"></script>
    <script src="javascripts/respond.js"></script>
    <!--[if lt IE 9]>
      <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    <!--[if lt IE 8]>
    <link rel="stylesheet" href="stylesheets/ie.css">
    <![endif]-->
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">

  </head>
  <body>
      <div id="header">
        <nav>
          <li class="fork"><a href="https://github.com/hellosangram/imageclassifiercaffe">View On GitHub</a></li>
          <li class="downloads"><a href="https://github.com/hellosangram/imageclassifiercaffe/zipball/master">ZIP</a></li>
          <li class="downloads"><a href="https://github.com/hellosangram/imageclassifiercaffe/tarball/master">TAR</a></li>
          <li class="title">DOWNLOADS</li>
        </nav>
      </div><!-- end header -->

    <div class="wrapper">

      <section>
        <div id="title">
          <h1>Image Classifier Caffe</h1>
          <p>Tutorial on how to setup a machine for a Deep Learning application, in this case Image Classification.  </p>
          <hr>
          <span class="credits left">Project maintained by <a href="https://github.com/hellosangram">hellosangram</a></span>
          <span class="credits right">Hosted on GitHub Pages &mdash; Theme by <a href="https://twitter.com/michigangraham">mattgraham</a></span>
        </div>

        <h3>
<a id="part-1-setting-up-the-machine-for-deep-learning" class="anchor" href="#part-1-setting-up-the-machine-for-deep-learning" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Part 1: Setting up the machine for Deep Learning.</h3>

<p>This guide is intended for people with similar laptop configurations as mine. I have an *<strong><em>Asus301U, i5 4th Gen CPU, 8gB RAM, 2gb Nvidia Graphics Card 940M, UEFI BIOS system and Ubuntu 16.04 installed as a dual-boot option.</em></strong>*<br>
Minor hiccups might come during the installation but that is the fun part to figure them out and I will leave them upto the individuals as most of them have already been resolved and just needs some digging.</p>

<h3>
<a id="installation-of-cuda" class="anchor" href="#installation-of-cuda" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Installation of Cuda</h3>

<p>First thing to remember is that Cuda and Ubuntu versions should be inter compatible, I initially chose Cuda7.5 with Ubuntu 16.04, and it did not along well thus I had to reinstall Cuda8.0 to have it run on my machine. I will abstain from repeating the information again and thus post threads of people who have already listed the procedure.<br>
Follow this thread for Cuda installation. <a href="http://askubuntu.com/questions/799184/how-can-i-install-cuda-on-ubuntu-16-04">http://askubuntu.com/questions/799184/how-can-i-install-cuda-on-ubuntu-16-04</a>
Problems you might encounter and how you might resolve them.</p>

<ul>
<li>Give permission for UEFI insecure boot if required, this will allow your Nvidia Graphics card drivers to work.</li>
<li>Stop lightdm server by pressing ctr+alt+f2 and then stopping it. Go ahead finish the cuda installation and restart it.</li>
<li>Cuda sometimes install old drivers for graphics card, please update them accordingly. This is useful to resolve the issue of infinite loop login screen appearance.</li>
<li>Check Cuda version and your Graphics cards installation with standard commands.</li>
</ul>

<h3>
<a id="installation-of-caffe" class="anchor" href="#installation-of-caffe" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Installation of Caffe</h3>

<p>Follow the link. <a href="http://caffe.berkeleyvision.org/install_apt.html">http://caffe.berkeleyvision.org/install_apt.html</a> along with <a href="http://hanzratech.in/2015/07/27/installing-caffe-on-ubuntu.html">http://hanzratech.in/2015/07/27/installing-caffe-on-ubuntu.html</a>
Remember to set your CPU and GPU flags according to your system specifications.
Don't forget to update your .bashrc file with the paths for future ease of use.
Update all the prerequisites so as to follow a smooth functioning.</p>

<h3>
<a id="some-basics-about-training-your-models" class="anchor" href="#some-basics-about-training-your-models" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Some basics about training your models.</h3>

<p>After you install caffe, you might have some models downloaded by default in your caffe file system, if need be then download their pre-trained files too.<br>
Now for every training you have got three options to either retrain the whole network from scratch, fine tune an existing model, freeze certain layers and just modify the layers you require. Most of the time it depends on the use case on which one to adopt. </p>

<h3>
<a id="part-2-image-classifier-for-isbi-challenge-on-analysis-of-images-to-detect-abnormalities-in-endoscopy-aida-e" class="anchor" href="#part-2-image-classifier-for-isbi-challenge-on-analysis-of-images-to-detect-abnormalities-in-endoscopy-aida-e" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Part 2: Image Classifier for ISBI Challenge on Analysis of Images to Detect Abnormalities in Endoscopy (AIDA-E)</h3>

<p>Link to the challenge: <a href="https://isbi-aida.grand-challenge.org/">https://isbi-aida.grand-challenge.org/</a>
My goal to complete the challenge in minimum time was the biggest critereon, this methodology should never be allowed in machine learning as each problem requires gestation before attack. I also preferred using AlexNet CNN and not any other as the images provided were of infinitesimal magnitude in comparison to ImageNet dataset which means many of the better performing models were large and prone to over-fitting.<br>
Another reason for choosing this network was due to my computer specifications which unfortunately could not support any bigger model without reducing batch size which if reduced too much might affect accuracy along with the standard affect of time.<br>
To overcome the small dataset problem I used Keras libary for data augmentation which is fabolous to use. But again too much of augmentation from the same images can not help you save from over fitting.  </p>

<h3>
<a id="model-selection" class="anchor" href="#model-selection" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Model Selection</h3>

<ul>
<li>
<em>GoogleLeNet Caffe Implementation</em> Present in Caffe Zoo, this model is very powerful when used for image classification. The drawback when I used was that it was too large too fit in my GPU memory and I saw preliminary results which showed superior prediction results on train image dataset and not on test image dataset. I used fine tuning of the model trained on ImageNet dataset. </li>
<li>
<em>Siamses Network</em> It is generally used for image similarity, but the unique thing is after training. It can be used on an image to detect its similarity to other just by giving one test image. I did not use this network due to the primary reason of implementation, for me I would have required to upload multiple images and create a median vector which could have then compared to test images. Theoretically sounds good but such implementation was nowhere to be found.</li>
<li>
<em>Alexnet Caffe Implementation</em> I used this network for its lack of magnitude of complexity and thus saving me from over-fitting in my case. The batch size I used was 64 which was decent considering the configuration of my laptop. I used freezing of certain layers and then finetuning of the last two layers. One change was to reduce the output paramter in fc7 from 4096 to 2048 and the other increasing the dropout to .75. These were done to reduce the oft used word by me "over fitting". I of course changed the output from 1000 in case of imagenet to 4 for our cases and the locations.<br>
</li>
</ul>

<h3>
<a id="data-manipulation" class="anchor" href="#data-manipulation" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Data Manipulation</h3>

<p><em>Data Augmentation</em> I used Keras library for data augmentation, the inbuilt function ImageDataGenerator created for a kaggle challenge and later adopted in the library is a beautiful and time saving tool.<br>
<em>Data Resizing</em> I resized the data from standard 227<em>227 used for ImageNet to 1024</em>1024 which would surely have helped as medical images are very sensitive to data loss and I wanted to avoid that. But alas my laptop could not support loading such a monstrous dataset and I had to maroon the idea alone.<br>
<em>Data Division</em> This idea came in but too late to implement that I could have created 20 images from one image of 1024<em>1024 by using standard 227</em>227 image thus making the data more mixed without augmentation.<br>
<em>Feature Marking in Data</em> I was reading Kaggle competition for detecting individual whales by spotting their spouts and identifying it with them. They too had a small dataset of 4000(yes way bigger than ours but still). The approach they took was to make the network focus on those features, I wanted to implement this but it was a moonshot considering data annotation and introduction of a data layer for the network to have some manual features added.</p>

<h3>
<a id="part3-run-the-implementation" class="anchor" href="#part3-run-the-implementation" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Part3: Run the implementation.</h3>

<p><em>Run: createData.py</em> A script to change the nomenclature to one I find suitable for easy use.<br>
<em>Run: dataAugmentation.py</em> For creating augmented data.<br>
<strong>Either</strong> <em>Run: createLmdb.py</em> Creates lmdb files for caffe to pick and process. Use this if data is not big.<br>
<strong>Or</strong> * <em>Run: createLmdbTxt.py</em> Creates txt file containing the relative image paths for the ensuing .sh file<br>
       * <em>Run: create_lmdb.sh</em> Used this .sh file as suggested in caffe issues if the data set becomes too large to hold in the memory, this files processes thousand at one time thus a life saver when I tested 1024*1024 images in AlexNet.  </p>

<p>Create binary proto file for mean values using /home/sangram/caffe/build/tools/caffe train --solver=/home/sangram/deepLearning/deeplearning-medical-images/caffe_models/caffe_model_2/solver_2.prototxt 2&gt;&amp;1 | tee /home/sangram/deepLearning/deeplearning-medical-images/caffe_models/caffe_model_2/model_2_train.log command on terminal</p>

<p>Train Model: /home/sangram/caffe/build/tools/caffe train --solver=/home/sangram/deepLearning/deeplearning-medical-images/caffe_models/caffe_model_2/solver_2.prototxt --weights /home/sangram/caffe/models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel 2&gt;&amp;1 | tee /home/sangram/deepLearning/deeplearning-medical-images/caffe_models/caffe_model_2/model_2_train.log</p>

<p><em>Run: makePredictions.py</em> This will give you the output predictions which you can use for checking accuracy and other functions. I used excel as accuracy is just a unitary method to implement. </p>

<h3>
<a id="support-or-contact" class="anchor" href="#support-or-contact" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Support or Contact</h3>

<p><a href="mailto:sangram.gupta@gmail.com">sangram.gupta@gmail.com</a> </p>
      </section>

    </div>
    <!--[if !IE]><script>fixScale(document);</script><![endif]-->
    
  </body>
</html>
